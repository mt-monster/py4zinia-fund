"""
åŸºé‡‘ç›¸å…³æ€§åˆ†æå·¥å…·
==================
ç”¨äºè®¡ç®—ä¸¤åªåŸºé‡‘ä¹‹é—´çš„ç›¸å…³æ€§ï¼ŒåŒ…æ‹¬æ—¥æ”¶ç›Šç‡ç›¸å…³æ€§ã€æ»šåŠ¨ç›¸å…³æ€§ã€ä¸åŒå‘¨æœŸç›¸å…³æ€§ç­‰ã€‚

ä½¿ç”¨æ–¹æ³•:
    python fund_correlation_analysis.py

ä½œè€…: AI Assistant
æ—¥æœŸ: 2026-02-05
"""

import akshare as ak
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # è®¾ç½®matplotlibåç«¯ä¸ºéGUIæ¨¡å¼
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from scipy import stats
import seaborn as sns

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒï¼ˆWindowsä¼˜å…ˆä½¿ç”¨å¾®è½¯é›…é»‘ï¼‰
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# ============== é…ç½®å‚æ•° ==============
# åŸºé‡‘ä»£ç å’Œåç§°
FUND_1_CODE = "002179"  # åå®‰äº‹ä»¶é©±åŠ¨é‡åŒ–æ··åˆA
FUND_1_NAME = "åå®‰äº‹ä»¶é©±åŠ¨é‡åŒ–æ··åˆA"

FUND_2_CODE = "013277"  # å¯Œå›½åˆ›ä¸šæ¿ETFè”æ¥C
FUND_2_NAME = "å¯Œå›½åˆ›ä¸šæ¿ETFè”æ¥C"

# åˆ†æèµ·å§‹æ—¥æœŸ (å¯é€‰)
START_DATE = None  # ä¾‹å¦‚: "2023-01-01", Noneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ•°æ®

# æ»šåŠ¨çª—å£å¤©æ•°
ROLLING_WINDOW = 60

# è¾“å‡ºå›¾è¡¨è·¯å¾„
OUTPUT_CHART = "fund_correlation_analysis.png"


# ============== æ ¸å¿ƒå‡½æ•° ==============

def fetch_fund_nav(fund_code: str, fund_name: str) -> pd.DataFrame:
    """
    è·å–åŸºé‡‘å†å²å‡€å€¼æ•°æ®
    
    å‚æ•°:
        fund_code: åŸºé‡‘ä»£ç 
        fund_name: åŸºé‡‘åç§°
    
    è¿”å›:
        DataFrameåŒ…å«å‡€å€¼æ—¥æœŸå’Œå•ä½å‡€å€¼
    """
    print(f"æ­£åœ¨è·å– {fund_name}({fund_code}) çš„æ•°æ®...")
    nav_data = ak.fund_open_fund_info_em(symbol=fund_code, indicator="å•ä½å‡€å€¼èµ°åŠ¿")
    nav_data['å‡€å€¼æ—¥æœŸ'] = pd.to_datetime(nav_data['å‡€å€¼æ—¥æœŸ'])
    nav_data = nav_data.sort_values('å‡€å€¼æ—¥æœŸ')
    nav_data = nav_data.rename(columns={'å•ä½å‡€å€¼': 'nav'})
    
    print(f"âœ… {fund_name} æ•°æ®è·å–æˆåŠŸ")
    print(f"   æ•°æ®èŒƒå›´: {nav_data['å‡€å€¼æ—¥æœŸ'].min().strftime('%Y-%m-%d')} è‡³ {nav_data['å‡€å€¼æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
    print(f"   æ•°æ®æ¡æ•°: {len(nav_data)}")
    
    return nav_data


def calculate_returns(nav_data: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—æ—¥æ”¶ç›Šç‡
    
    å‚æ•°:
        nav_data: åŒ…å«navåˆ—çš„DataFrame
    
    è¿”å›:
        æ·»åŠ äº†returnåˆ—çš„DataFrame
    """
    data = nav_data.copy()
    data['return'] = data['nav'].pct_change() * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    return data.dropna()


def calculate_correlation(returns_1: pd.Series, returns_2: pd.Series) -> dict:
    """
    è®¡ç®—å¤šç§ç›¸å…³ç³»æ•°
    
    å‚æ•°:
        returns_1: åŸºé‡‘1çš„æ”¶ç›Šç‡åºåˆ—
        returns_2: åŸºé‡‘2çš„æ”¶ç›Šç‡åºåˆ—
    
    è¿”å›:
        åŒ…å«å„ç§ç›¸å…³ç³»æ•°çš„å­—å…¸
    """
    # çš®å°”é€Šç›¸å…³ç³»æ•° (çº¿æ€§ç›¸å…³)
    pearson_corr, pearson_p = stats.pearsonr(returns_1, returns_2)
    
    # æ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•° (ç§©ç›¸å…³)
    spearman_corr, spearman_p = stats.spearmanr(returns_1, returns_2)
    
    # è‚¯å¾·å°”ç›¸å…³ç³»æ•°
    kendall_corr, kendall_p = stats.kendalltau(returns_1, returns_2)
    
    return {
        'pearson': {'corr': pearson_corr, 'p_value': pearson_p},
        'spearman': {'corr': spearman_corr, 'p_value': spearman_p},
        'kendall': {'corr': kendall_corr, 'p_value': kendall_p}
    }


def interpret_correlation(corr: float) -> str:
    """
    è§£è¯»ç›¸å…³ç³»æ•°çš„å¼ºåº¦
    
    å‚æ•°:
        corr: ç›¸å…³ç³»æ•°å€¼
    
    è¿”å›:
        ç›¸å…³æ€§å¼ºåº¦æè¿°
    """
    abs_corr = abs(corr)
    if abs_corr >= 0.8:
        strength = "æå¼ºç›¸å…³"
    elif abs_corr >= 0.6:
        strength = "å¼ºç›¸å…³"
    elif abs_corr >= 0.4:
        strength = "ä¸­ç­‰ç›¸å…³"
    elif abs_corr >= 0.2:
        strength = "å¼±ç›¸å…³"
    else:
        strength = "æå¼±ç›¸å…³æˆ–æ— ç›¸å…³"
    
    direction = "æ­£ç›¸å…³" if corr > 0 else "è´Ÿç›¸å…³"
    return f"{strength} ({direction})"


def calculate_rolling_correlation(returns_1: pd.Series, returns_2: pd.Series, 
                                   window: int = 60) -> pd.Series:
    """
    è®¡ç®—æ»šåŠ¨ç›¸å…³ç³»æ•°
    
    å‚æ•°:
        returns_1: åŸºé‡‘1çš„æ”¶ç›Šç‡åºåˆ—
        returns_2: åŸºé‡‘2çš„æ”¶ç›Šç‡åºåˆ—
        window: æ»šåŠ¨çª—å£å¤§å°
    
    è¿”å›:
        æ»šåŠ¨ç›¸å…³ç³»æ•°åºåˆ—
    """
    return returns_1.rolling(window=window).corr(returns_2)


def calculate_period_correlation(nav_1: pd.Series, nav_2: pd.Series, 
                                  period: int) -> float:
    """
    è®¡ç®—æŒ‡å®šå‘¨æœŸçš„æ”¶ç›Šç‡ç›¸å…³æ€§
    
    å‚æ•°:
        nav_1: åŸºé‡‘1çš„å‡€å€¼åºåˆ—
        nav_2: åŸºé‡‘2çš„å‡€å€¼åºåˆ—
        period: å‘¨æœŸå¤©æ•°
    
    è¿”å›:
        ç›¸å…³ç³»æ•°
    """
    ret_1 = nav_1.pct_change(period) * 100
    ret_2 = nav_2.pct_change(period) * 100
    return ret_1.corr(ret_2)


def plot_correlation_analysis(merged_data: pd.DataFrame, returns_data: pd.DataFrame,
                               corr_results: dict, fund_1_name: str, fund_2_name: str,
                               output_path: str):
    """
    ç»˜åˆ¶ç›¸å…³æ€§åˆ†æå›¾è¡¨
    
    å‚æ•°:
        merged_data: åˆå¹¶åçš„å‡€å€¼æ•°æ®
        returns_data: æ”¶ç›Šç‡æ•°æ®
        corr_results: ç›¸å…³æ€§ç»“æœå­—å…¸
        fund_1_name: åŸºé‡‘1åç§°
        fund_2_name: åŸºé‡‘2åç§°
        output_path: è¾“å‡ºå›¾è¡¨è·¯å¾„
    """
    pearson_corr = corr_results['pearson']['corr']
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle(f'åŸºé‡‘ç›¸å…³æ€§åˆ†æ: {fund_1_name} vs {fund_2_name}', 
                 fontsize=14, fontweight='bold')
    
    # 1. æ•£ç‚¹å›¾
    ax1 = axes[0, 0]
    ax1.scatter(returns_data['return_2'], returns_data['return_1'], 
                alpha=0.5, s=20, c='steelblue', edgecolors='none')
    z = np.polyfit(returns_data['return_2'], returns_data['return_1'], 1)
    p = np.poly1d(z)
    ax1.plot(returns_data['return_2'], p(returns_data['return_2']), 
             "r--", linewidth=2, label=f'è¶‹åŠ¿çº¿: y={z[0]:.3f}x+{z[1]:.3f}')
    ax1.set_xlabel(f'{fund_2_name} æ—¥æ”¶ç›Šç‡ (%)', fontsize=10)
    ax1.set_ylabel(f'{fund_1_name} æ—¥æ”¶ç›Šç‡ (%)', fontsize=10)
    ax1.set_title(f'æ—¥æ”¶ç›Šç‡æ•£ç‚¹å›¾ (Pearson r={pearson_corr:.4f})', fontsize=11)
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='k', linestyle='-', linewidth=0.5)
    ax1.axvline(x=0, color='k', linestyle='-', linewidth=0.5)
    
    # 2. å‡€å€¼èµ°åŠ¿å¯¹æ¯”
    ax2 = axes[0, 1]
    norm_1 = merged_data['nav_1'] / merged_data['nav_1'].iloc[0] * 100
    norm_2 = merged_data['nav_2'] / merged_data['nav_2'].iloc[0] * 100
    ax2.plot(merged_data['å‡€å€¼æ—¥æœŸ'], norm_1, label=fund_1_name, 
             linewidth=1.5, color='#1f77b4')
    ax2.plot(merged_data['å‡€å€¼æ—¥æœŸ'], norm_2, label=fund_2_name, 
             linewidth=1.5, color='#ff7f0e')
    ax2.set_xlabel('æ—¥æœŸ', fontsize=10)
    ax2.set_ylabel('å½’ä¸€åŒ–å‡€å€¼ (èµ·å§‹=100)', fontsize=10)
    ax2.set_title('å‡€å€¼èµ°åŠ¿å¯¹æ¯” (å½’ä¸€åŒ–)', fontsize=11)
    ax2.legend(loc='upper left')
    ax2.grid(True, alpha=0.3)
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax2.xaxis.set_major_locator(mdates.MonthLocator(interval=6))
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    # 3. æ»šåŠ¨ç›¸å…³æ€§
    ax3 = axes[1, 0]
    rolling_corr = calculate_rolling_correlation(
        returns_data['return_1'], returns_data['return_2'], ROLLING_WINDOW
    )
    ax3.plot(returns_data['å‡€å€¼æ—¥æœŸ'], rolling_corr, linewidth=1.5, color='green')
    ax3.axhline(y=pearson_corr, color='r', linestyle='--', linewidth=1.5, 
                label=f'æ•´ä½“ç›¸å…³æ€§: {pearson_corr:.4f}')
    ax3.set_xlabel('æ—¥æœŸ', fontsize=10)
    ax3.set_ylabel(f'æ»šåŠ¨ç›¸å…³ç³»æ•° ({ROLLING_WINDOW}æ—¥)', fontsize=10)
    ax3.set_title(f'æ»šåŠ¨ç›¸å…³æ€§å˜åŒ– ({ROLLING_WINDOW}æ—¥çª—å£)', fontsize=11)
    ax3.legend(loc='lower right')
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim(-1, 1)
    ax3.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax3.xaxis.set_major_locator(mdates.MonthLocator(interval=6))
    plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    # 4. æ”¶ç›Šç‡åˆ†å¸ƒ
    ax4 = axes[1, 1]
    bins = np.linspace(-10, 10, 50)
    ax4.hist(returns_data['return_1'], bins=bins, alpha=0.6, 
             label=fund_1_name, color='#1f77b4', density=True)
    ax4.hist(returns_data['return_2'], bins=bins, alpha=0.6, 
             label=fund_2_name, color='#ff7f0e', density=True)
    ax4.set_xlabel('æ—¥æ”¶ç›Šç‡ (%)', fontsize=10)
    ax4.set_ylabel('æ¦‚ç‡å¯†åº¦', fontsize=10)
    ax4.set_title('æ—¥æ”¶ç›Šç‡åˆ†å¸ƒå¯¹æ¯”', fontsize=11)
    ax4.legend(loc='upper right')
    ax4.grid(True, alpha=0.3)
    ax4.axvline(x=0, color='k', linestyle='-', linewidth=0.5)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… å›¾è¡¨å·²ä¿å­˜è‡³: {output_path}")
    plt.show()


def print_analysis_report(fund_1_name: str, fund_2_name: str,
                          corr_results: dict, sample_size: int,
                          start_date: str, end_date: str):
    """
    æ‰“å°åˆ†ææŠ¥å‘Š
    
    å‚æ•°:
        fund_1_name: åŸºé‡‘1åç§°
        fund_2_name: åŸºé‡‘2åç§°
        corr_results: ç›¸å…³æ€§ç»“æœå­—å…¸
        sample_size: æ ·æœ¬æ•°é‡
        start_date: èµ·å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
    """
    pearson = corr_results['pearson']
    spearman = corr_results['spearman']
    kendall = corr_results['kendall']
    
    print("\n" + "=" * 70)
    print("ğŸ“Š åŸºé‡‘ç›¸å…³æ€§åˆ†ææŠ¥å‘Š")
    print("=" * 70)
    print(f"\nåŸºé‡‘1: {fund_1_name}")
    print(f"åŸºé‡‘2: {fund_2_name}")
    print(f"åˆ†ææœŸé—´: {start_date} è‡³ {end_date}")
    print(f"æ ·æœ¬æ•°é‡: {sample_size} ä¸ªäº¤æ˜“æ—¥")
    
    print("\n" + "-" * 70)
    print("ğŸ“ˆ ç›¸å…³æ€§ç³»æ•°:")
    print("-" * 70)
    print(f"  çš®å°”é€Šç›¸å…³ç³»æ•° (Pearson):   {pearson['corr']:.4f} (på€¼: {pearson['p_value']:.2e})")
    print(f"  æ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•° (Spearman): {spearman['corr']:.4f} (på€¼: {spearman['p_value']:.2e})")
    print(f"  è‚¯å¾·å°”ç›¸å…³ç³»æ•° (Kendall):    {kendall['corr']:.4f} (på€¼: {kendall['p_value']:.2e})")
    print("-" * 70)
    
    interpretation = interpret_correlation(pearson['corr'])
    print(f"\nğŸ“‹ ç»“è®º: ä¸¤åªåŸºé‡‘å‘ˆ {interpretation}")
    print("=" * 70)


# ============== ä¸»ç¨‹åº ==============

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("åŸºé‡‘ç›¸å…³æ€§åˆ†æå·¥å…·")
    print("=" * 70)
    
    # 1. è·å–åŸºé‡‘æ•°æ®
    fund_1_nav = fetch_fund_nav(FUND_1_CODE, FUND_1_NAME)
    fund_2_nav = fetch_fund_nav(FUND_2_CODE, FUND_2_NAME)
    
    # 2. æ•°æ®å¯¹é½
    merged_data = pd.merge(
        fund_1_nav[['å‡€å€¼æ—¥æœŸ', 'nav']].rename(columns={'nav': 'nav_1'}),
        fund_2_nav[['å‡€å€¼æ—¥æœŸ', 'nav']].rename(columns={'nav': 'nav_2'}),
        on='å‡€å€¼æ—¥æœŸ',
        how='inner'
    )
    
    # æ ¹æ®èµ·å§‹æ—¥æœŸç­›é€‰
    if START_DATE:
        merged_data = merged_data[merged_data['å‡€å€¼æ—¥æœŸ'] >= START_DATE]
    
    print(f"\nå¯¹é½åçš„æ•°æ®æ¡æ•°: {len(merged_data)}")
    print(f"å…±åŒæ•°æ®èŒƒå›´: {merged_data['å‡€å€¼æ—¥æœŸ'].min().strftime('%Y-%m-%d')} è‡³ {merged_data['å‡€å€¼æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
    
    # 3. è®¡ç®—æ”¶ç›Šç‡
    merged_data['return_1'] = merged_data['nav_1'].pct_change() * 100
    merged_data['return_2'] = merged_data['nav_2'].pct_change() * 100
    returns_data = merged_data.dropna()
    
    # 4. è®¡ç®—ç›¸å…³æ€§
    corr_results = calculate_correlation(
        returns_data['return_1'], 
        returns_data['return_2']
    )
    
    # 5. æ‰“å°æŠ¥å‘Š
    print_analysis_report(
        FUND_1_NAME, FUND_2_NAME,
        corr_results, len(returns_data),
        returns_data['å‡€å€¼æ—¥æœŸ'].min().strftime('%Y-%m-%d'),
        returns_data['å‡€å€¼æ—¥æœŸ'].max().strftime('%Y-%m-%d')
    )
    
    # 6. è®¡ç®—ä¸åŒå‘¨æœŸçš„ç›¸å…³æ€§
    print("\nğŸ“Š ä¸åŒå‘¨æœŸæ”¶ç›Šç‡ç›¸å…³æ€§:")
    periods = [5, 10, 20, 60]
    period_names = ['å‘¨æ”¶ç›Š(5æ—¥)', 'åŒå‘¨æ”¶ç›Š(10æ—¥)', 'æœˆæ”¶ç›Š(20æ—¥)', 'å­£åº¦æ”¶ç›Š(60æ—¥)']
    for p, name in zip(periods, period_names):
        corr_p = calculate_period_correlation(
            merged_data['nav_1'], merged_data['nav_2'], p
        )
        print(f"  {name}: {corr_p:.4f}")
    
    # 7. ç»˜åˆ¶å›¾è¡¨
    plot_correlation_analysis(
        merged_data, returns_data,
        corr_results, FUND_1_NAME, FUND_2_NAME,
        OUTPUT_CHART
    )


if __name__ == "__main__":
    main()
