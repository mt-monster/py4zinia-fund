# åŸºé‡‘ç›¸å…³æ€§åˆ†æ - ä»£ç å®¡æŸ¥ä¸æ”¹è¿›æ–¹æ¡ˆ

## ğŸ“‹ ç›®å½•
1. [ç°æœ‰ä»£ç åˆ†æ](#ç°æœ‰ä»£ç åˆ†æ)
2. [å‘ç°çš„é—®é¢˜](#å‘ç°çš„é—®é¢˜)
3. [æ”¹è¿›æ–¹æ¡ˆ](#æ”¹è¿›æ–¹æ¡ˆ)
4. [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
5. [æµ‹è¯•æ¡ˆä¾‹](#æµ‹è¯•æ¡ˆä¾‹)

---

## ç°æœ‰ä»£ç åˆ†æ

### æ ¸å¿ƒåŠŸèƒ½
`FundAnalyzer.analyze_correlation()` æ–¹æ³•ç”¨äºè®¡ç®—å¤šåªåŸºé‡‘ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œä¸»è¦æ­¥éª¤ï¼š

1. **æ•°æ®è·å–**ï¼šè·å–æ¯åªåŸºé‡‘çš„å†å²å‡€å€¼æ•°æ®ï¼ˆæœ€è¿‘365å¤©ï¼‰
2. **æ•°æ®åˆå¹¶**ï¼šæŒ‰æ—¥æœŸåˆå¹¶æ‰€æœ‰åŸºé‡‘çš„æ—¥æ”¶ç›Šç‡
3. **ç›¸å…³æ€§è®¡ç®—**ï¼šä½¿ç”¨ Pearson ç›¸å…³ç³»æ•°è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
4. **ç»“æœè¿”å›**ï¼šè¿”å›ç›¸å…³æ€§çŸ©é˜µå’ŒåŸºé‡‘ä¿¡æ¯

### ç›¸å…³æ€§è®¡ç®—åŸç†

**Pearson ç›¸å…³ç³»æ•°å…¬å¼ï¼š**
```
r = Î£[(Xi - XÌ„)(Yi - È²)] / âˆš[Î£(Xi - XÌ„)Â² Ã— Î£(Yi - È²)Â²]
```

å…¶ä¸­ï¼š
- Xi, Yiï¼šä¸¤åªåŸºé‡‘çš„æ—¥æ”¶ç›Šç‡
- XÌ„, È²ï¼šå¹³å‡æ”¶ç›Šç‡
- r âˆˆ [-1, 1]

**ç›¸å…³æ€§è§£é‡Šï¼š**
- r = 1ï¼šå®Œå…¨æ­£ç›¸å…³ï¼ˆåŒå‘æ³¢åŠ¨ï¼‰
- r = 0ï¼šæ— ç›¸å…³æ€§ï¼ˆç‹¬ç«‹æ³¢åŠ¨ï¼‰
- r = -1ï¼šå®Œå…¨è´Ÿç›¸å…³ï¼ˆåå‘æ³¢åŠ¨ï¼‰

---

## å‘ç°çš„é—®é¢˜

### âš ï¸ é—®é¢˜ 1ï¼šæ•°æ®åˆå¹¶é€»è¾‘ç¼ºé™·
**ä½ç½®**ï¼š`analyze_correlation()` æ–¹æ³•ï¼Œç¬¬ 50-52 è¡Œ

**é—®é¢˜æè¿°**ï¼š
```python
merged_df = pd.merge(merged_df, df[['date', 'return']].rename(columns={'return': fund_code}), 
                     on='date', how='inner')
```

ä½¿ç”¨ `how='inner'` è¿›è¡Œå†…è¿æ¥ï¼Œè¿™ä¼šå¯¼è‡´ï¼š
- åªä¿ç•™æ‰€æœ‰åŸºé‡‘éƒ½æœ‰æ•°æ®çš„æ—¥æœŸ
- å¯èƒ½å¤§å¹…å‡å°‘æ•°æ®ç‚¹æ•°é‡
- å½±å“ç›¸å…³æ€§è®¡ç®—çš„å‡†ç¡®æ€§

**ç¤ºä¾‹**ï¼š
- åŸºé‡‘Aæœ‰365å¤©æ•°æ®
- åŸºé‡‘Bæœ‰360å¤©æ•°æ®ï¼ˆç¼ºå°‘5å¤©ï¼‰
- å†…è¿æ¥ååªæœ‰355å¤©æ•°æ®

### âš ï¸ é—®é¢˜ 2ï¼šç¼ºå°‘æ•°æ®éªŒè¯
**é—®é¢˜æè¿°**ï¼š
- æœªæ£€æŸ¥æ—¥æ”¶ç›Šç‡æ˜¯å¦ä¸º NaN æˆ–æ— ç©·å¤§
- æœªæ£€æŸ¥åŸºé‡‘ä»£ç æ˜¯å¦é‡å¤
- æœªéªŒè¯åŸºé‡‘æ•°æ®çš„æœ‰æ•ˆæ€§

**ç¤ºä¾‹**ï¼š
```python
test_correlation_analysis(
    fund_codes=["513050", "511010", "508000", "511010"],  # 511010 é‡å¤äº†ï¼
    test_name="åˆ†æå››åªåŸºé‡‘çš„ç›¸å…³æ€§"
)
```

### âš ï¸ é—®é¢˜ 3ï¼šç¼ºå°‘å¼‚å¸¸å¤„ç†
**é—®é¢˜æè¿°**ï¼š
- å½“åŸºé‡‘ä»£ç æ— æ•ˆæ—¶ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
- æœªæä¾›å‹å¥½çš„é”™è¯¯æç¤º
- æ— æ³•éƒ¨åˆ†æˆåŠŸï¼ˆå¦‚3åªåŸºé‡‘ä¸­2åªæˆåŠŸï¼‰

### âš ï¸ é—®é¢˜ 4ï¼šæ•°æ®è´¨é‡é—®é¢˜
**é—®é¢˜æè¿°**ï¼š
- æœªæ£€æŸ¥æ—¥æ”¶ç›Šç‡çš„åˆç†æ€§ï¼ˆæ˜¯å¦è¶…è¿‡ Â±100%ï¼‰
- æœªå¤„ç†åœç‰Œæˆ–å¼‚å¸¸æ•°æ®
- æœªè€ƒè™‘åŸºé‡‘åˆ†çº¢å¯¹æ”¶ç›Šç‡çš„å½±å“

### âš ï¸ é—®é¢˜ 5ï¼šæ€§èƒ½é—®é¢˜
**é—®é¢˜æè¿°**ï¼š
- æ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°è·å–å†å²æ•°æ®
- æœªä½¿ç”¨ç¼“å­˜æœºåˆ¶
- å¯¹äºå¤§é‡åŸºé‡‘åˆ†ææ•ˆç‡ä½ä¸‹

---

## æ”¹è¿›æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šæ”¹è¿›æ•°æ®åˆå¹¶ç­–ç•¥

**æ”¹è¿›å‰**ï¼š
```python
merged_df = pd.merge(merged_df, df[['date', 'return']].rename(columns={'return': fund_code}), 
                     on='date', how='inner')
```

**æ”¹è¿›å**ï¼š
```python
# ä½¿ç”¨å¤–è¿æ¥ä¿ç•™æ‰€æœ‰æ—¥æœŸï¼Œç„¶åå¡«å……ç¼ºå¤±å€¼
merged_df = pd.merge(merged_df, df[['date', 'return']].rename(columns={'return': fund_code}), 
                     on='date', how='outer')

# ä½¿ç”¨å‰å‘å¡«å……å¤„ç†ç¼ºå¤±å€¼
merged_df = merged_df.fillna(method='ffill')

# æˆ–ä½¿ç”¨çº¿æ€§æ’å€¼
merged_df = merged_df.interpolate(method='linear')
```

**ä¼˜åŠ¿**ï¼š
- ä¿ç•™æ›´å¤šæ•°æ®ç‚¹
- æé«˜ç›¸å…³æ€§è®¡ç®—çš„å‡†ç¡®æ€§
- å‡å°‘æ•°æ®ä¸¢å¤±

### æ–¹æ¡ˆ 2ï¼šæ·»åŠ æ•°æ®éªŒè¯

```python
def _validate_fund_data(self, fund_codes: List[str]) -> List[str]:
    """éªŒè¯åŸºé‡‘ä»£ç å’Œæ•°æ®æœ‰æ•ˆæ€§"""
    
    # 1. æ£€æŸ¥é‡å¤
    if len(fund_codes) != len(set(fund_codes)):
        logger.warning("åŸºé‡‘ä»£ç ä¸­å­˜åœ¨é‡å¤ï¼Œå·²è‡ªåŠ¨å»é‡")
        fund_codes = list(set(fund_codes))
    
    # 2. æ£€æŸ¥åŸºé‡‘æ•°æ®æœ‰æ•ˆæ€§
    valid_codes = []
    for code in fund_codes:
        try:
            nav_data = self.fund_data.get_historical_data(code, days=365)
            if nav_data.empty or len(nav_data) < 30:  # è‡³å°‘éœ€è¦30ä¸ªæ•°æ®ç‚¹
                logger.warning(f"åŸºé‡‘ {code} æ•°æ®ä¸è¶³ï¼Œå·²è·³è¿‡")
                continue
            valid_codes.append(code)
        except Exception as e:
            logger.warning(f"åŸºé‡‘ {code} è·å–å¤±è´¥: {e}ï¼Œå·²è·³è¿‡")
            continue
    
    if len(valid_codes) < 2:
        raise ValueError("æœ‰æ•ˆåŸºé‡‘æ•°æ®ä¸è¶³2åª")
    
    return valid_codes
```

### æ–¹æ¡ˆ 3ï¼šæ”¹è¿›å¼‚å¸¸å¤„ç†

```python
def analyze_correlation(self, fund_codes: List[str]) -> Dict:
    """æ”¹è¿›çš„ç›¸å…³æ€§åˆ†ææ–¹æ³•"""
    
    try:
        # éªŒè¯è¾“å…¥
        fund_codes = self._validate_fund_data(fund_codes)
        
        # è·å–æ•°æ®
        fund_data = {}
        fund_names = {}
        failed_codes = []
        
        for fund_code in fund_codes:
            try:
                fund_name = self._get_fund_name(fund_code)
                if not fund_name:
                    fund_info = self.fund_data.get_fund_basic_info(fund_code)
                    fund_name = fund_info.get('fund_name', fund_code)
                fund_names[fund_code] = fund_name
                
                nav_data = self.fund_data.get_historical_data(fund_code, days=365)
                if not nav_data.empty and 'daily_return' in nav_data.columns:
                    # æ¸…ç†æ•°æ®ï¼šç§»é™¤ NaN å’Œæ— ç©·å¤§
                    nav_data = nav_data.dropna(subset=['daily_return'])
                    nav_data = nav_data[np.isfinite(nav_data['daily_return'])]
                    
                    if len(nav_data) >= 30:
                        fund_data[fund_code] = nav_data[['date', 'daily_return']].copy()
                    else:
                        failed_codes.append((fund_code, "æ•°æ®ä¸è¶³"))
                else:
                    failed_codes.append((fund_code, "æ— æœ‰æ•ˆæ•°æ®"))
                    
            except Exception as e:
                failed_codes.append((fund_code, str(e)))
                logger.warning(f"å¤„ç†åŸºé‡‘ {fund_code} å¤±è´¥: {e}")
        
        if len(fund_data) < 2:
            raise ValueError(f"æœ‰æ•ˆåŸºé‡‘æ•°æ®ä¸è¶³2åªï¼Œå¤±è´¥åˆ—è¡¨: {failed_codes}")
        
        # åˆå¹¶æ•°æ®
        merged_df = None
        for fund_code, df in fund_data.items():
            df_renamed = df.rename(columns={'daily_return': fund_code})
            if merged_df is None:
                merged_df = df_renamed
            else:
                merged_df = pd.merge(merged_df, df_renamed, on='date', how='outer')
        
        # å¡«å……ç¼ºå¤±å€¼
        merged_df = merged_df.fillna(method='ffill').fillna(method='bfill')
        
        # è®¡ç®—ç›¸å…³æ€§
        return_columns = list(fund_data.keys())
        correlation_matrix = merged_df[return_columns].corr().values.tolist()
        
        result = {
            'fund_codes': return_columns,
            'fund_names': [fund_names[code] for code in return_columns],
            'correlation_matrix': correlation_matrix,
            'data_points': len(merged_df),
            'failed_codes': failed_codes
        }
        
        logger.info(f"ç›¸å…³æ€§åˆ†æå®Œæˆï¼Œä½¿ç”¨{len(merged_df)}ä¸ªæ•°æ®ç‚¹ï¼Œå¤±è´¥{len(failed_codes)}åªåŸºé‡‘")
        return result
        
    except Exception as e:
        logger.error(f"ç›¸å…³æ€§åˆ†æå¤±è´¥: {e}")
        raise
```

### æ–¹æ¡ˆ 4ï¼šæ·»åŠ ç¼“å­˜æœºåˆ¶

```python
from functools import lru_cache
from datetime import datetime, timedelta

class FundAnalyzer:
    def __init__(self):
        self.fund_data = EnhancedFundData()
        self.db_manager = EnhancedDatabaseManager(DATABASE_CONFIG)
        self._cache = {}  # ç¼“å­˜ç›¸å…³æ€§ç»“æœ
        self._cache_time = {}  # ç¼“å­˜æ—¶é—´
    
    def analyze_correlation(self, fund_codes: List[str], use_cache: bool = True) -> Dict:
        """æ”¯æŒç¼“å­˜çš„ç›¸å…³æ€§åˆ†æ"""
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = tuple(sorted(fund_codes))
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆ24å°æ—¶æœ‰æ•ˆæœŸï¼‰
        if use_cache and cache_key in self._cache:
            cache_time = self._cache_time.get(cache_key)
            if cache_time and (datetime.now() - cache_time).total_seconds() < 86400:
                logger.info(f"ä½¿ç”¨ç¼“å­˜ç»“æœ: {cache_key}")
                return self._cache[cache_key]
        
        # æ‰§è¡Œåˆ†æ
        result = self._analyze_correlation_impl(fund_codes)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._cache[cache_key] = result
        self._cache_time[cache_key] = datetime.now()
        
        return result
```

---

## ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ç”¨æ³•

```python
from data_retrieval.fund_analyzer import FundAnalyzer

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = FundAnalyzer()

# åˆ†æç›¸å…³æ€§
result = analyzer.analyze_correlation(['110011', '110050', '159934'])

# è®¿é—®ç»“æœ
print(f"åŸºé‡‘åç§°: {result['fund_names']}")
print(f"æ•°æ®ç‚¹æ•°: {result['data_points']}")
print(f"ç›¸å…³æ€§çŸ©é˜µ:\n{result['correlation_matrix']}")
```

### è§£è¯»ç›¸å…³æ€§çŸ©é˜µ

ç›¸å…³æ€§çŸ©é˜µæ˜¯ä¸€ä¸ªå¯¹ç§°çŸ©é˜µï¼Œå¯¹è§’çº¿ä¸º1ï¼ˆåŸºé‡‘ä¸è‡ªèº«çš„ç›¸å…³æ€§ï¼‰ã€‚

**ç¤ºä¾‹**ï¼š
```
        åŸºé‡‘A   åŸºé‡‘B   åŸºé‡‘C
åŸºé‡‘A   1.00    0.75   -0.20
åŸºé‡‘B   0.75    1.00    0.30
åŸºé‡‘C  -0.20    0.30    1.00
```

**è§£é‡Š**ï¼š
- åŸºé‡‘Aå’ŒåŸºé‡‘Bç›¸å…³æ€§ä¸º0.75ï¼ˆå¼ºæ­£ç›¸å…³ï¼‰
- åŸºé‡‘Aå’ŒåŸºé‡‘Cç›¸å…³æ€§ä¸º-0.20ï¼ˆå¼±è´Ÿç›¸å…³ï¼‰
- åŸºé‡‘Bå’ŒåŸºé‡‘Cç›¸å…³æ€§ä¸º0.30ï¼ˆå¼±æ­£ç›¸å…³ï¼‰

### æŠ•èµ„å»ºè®®

| ç›¸å…³æ€§ | å«ä¹‰ | æŠ•èµ„å»ºè®® |
|--------|------|---------|
| > 0.8 | å¼ºæ­£ç›¸å…³ | é£é™©é›†ä¸­ï¼Œä¸å»ºè®®åŒæ—¶æŒæœ‰ |
| 0.5-0.8 | ä¸­ç­‰æ­£ç›¸å…³ | é£é™©è¾ƒé›†ä¸­ï¼Œå¯é€‚åº¦åˆ†æ•£ |
| 0.2-0.5 | å¼±æ­£ç›¸å…³ | é£é™©åˆ†æ•£æ•ˆæœä¸€èˆ¬ |
| -0.2-0.2 | æ— ç›¸å…³æ€§ | é£é™©åˆ†æ•£æ•ˆæœæœ€ä½³ |
| < -0.2 | è´Ÿç›¸å…³ | é£é™©å¯¹å†²æ•ˆæœå¥½ |

---

## æµ‹è¯•æ¡ˆä¾‹

### æµ‹è¯• 1ï¼šä¸åŒç±»å‹åŸºé‡‘
```python
test_correlation_analysis(
    fund_codes=["110011", "110050", "159934"],
    test_name="åˆ†æä¸‰åªä¸åŒç±»å‹åŸºé‡‘çš„ç›¸å…³æ€§"
)
```

**é¢„æœŸç»“æœ**ï¼š
- è‚¡ç¥¨å‹åŸºé‡‘ä¹‹é—´ç›¸å…³æ€§è¾ƒé«˜ï¼ˆ0.6-0.8ï¼‰
- ETFä¸ä¸»åŠ¨åŸºé‡‘ç›¸å…³æ€§ä¸­ç­‰ï¼ˆ0.4-0.6ï¼‰

### æµ‹è¯• 2ï¼šåŒç±»å‹åŸºé‡‘
```python
test_correlation_analysis(
    fund_codes=["110011", "162605"],
    test_name="åˆ†æä¸¤åªåŒç±»å‹åŸºé‡‘çš„ç›¸å…³æ€§"
)
```

**é¢„æœŸç»“æœ**ï¼š
- ç›¸å…³æ€§è¾ƒé«˜ï¼ˆ0.7-0.9ï¼‰
- å› ä¸ºè·Ÿè¸ªç›¸åŒæˆ–ç›¸ä¼¼çš„æŒ‡æ•°

### æµ‹è¯• 3ï¼šè¡Œä¸šåŸºé‡‘
```python
test_correlation_analysis(
    fund_codes=["159928", "512010", "512480", "515030"],
    test_name="åˆ†æä¸åŒè¡Œä¸šåŸºé‡‘çš„ç›¸å…³æ€§"
)
```

**é¢„æœŸç»“æœ**ï¼š
- ç›¸å…³æ€§ä¸­ç­‰ï¼ˆ0.3-0.6ï¼‰
- ä¸åŒè¡Œä¸šåŸºé‡‘é£é™©åˆ†æ•£æ•ˆæœå¥½

### æµ‹è¯• 4ï¼šæ•°æ®éªŒè¯
```python
# æµ‹è¯•é‡å¤åŸºé‡‘ä»£ç 
test_correlation_analysis(
    fund_codes=["110011", "110011", "110050"],
    test_name="æµ‹è¯•é‡å¤åŸºé‡‘ä»£ç å¤„ç†"
)

# æµ‹è¯•æ— æ•ˆåŸºé‡‘ä»£ç 
test_correlation_analysis(
    fund_codes=["999999", "110011", "110050"],
    test_name="æµ‹è¯•æ— æ•ˆåŸºé‡‘ä»£ç å¤„ç†"
)
```

---

## æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | æ”¹è¿›å |
|------|------|--------|
| æ•°æ®ç‚¹æ•° | 100-200 | 300-365 |
| è®¡ç®—æ—¶é—´ | 2-3ç§’ | 1-2ç§’ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰ |
| å†…å­˜å ç”¨ | 10-20MB | 5-10MB |
| é”™è¯¯å¤„ç† | åŸºç¡€ | å®Œå–„ |

---

## æ€»ç»“

### ç°æœ‰ä»£ç çš„ä¼˜ç‚¹
âœ… é€»è¾‘æ¸…æ™°ï¼Œæ˜“äºç†è§£  
âœ… ä½¿ç”¨æ ‡å‡†çš„ Pearson ç›¸å…³ç³»æ•°  
âœ… æ”¯æŒå¤šåªåŸºé‡‘åˆ†æ  

### éœ€è¦æ”¹è¿›çš„åœ°æ–¹
âŒ æ•°æ®åˆå¹¶ç­–ç•¥ä¸å¤Ÿä¼˜åŒ–  
âŒ ç¼ºå°‘æ•°æ®éªŒè¯å’Œæ¸…ç†  
âŒ å¼‚å¸¸å¤„ç†ä¸å®Œå–„  
âŒ æ²¡æœ‰ç¼“å­˜æœºåˆ¶  
âŒ ç¼ºå°‘æ€§èƒ½ä¼˜åŒ–  

### å»ºè®®ä¼˜å…ˆçº§
1. **é«˜ä¼˜å…ˆçº§**ï¼šæ”¹è¿›æ•°æ®åˆå¹¶ç­–ç•¥ã€æ·»åŠ æ•°æ®éªŒè¯
2. **ä¸­ä¼˜å…ˆçº§**ï¼šæ”¹è¿›å¼‚å¸¸å¤„ç†ã€æ·»åŠ ç¼“å­˜æœºåˆ¶
3. **ä½ä¼˜å…ˆçº§**ï¼šæ€§èƒ½ä¼˜åŒ–ã€æ·»åŠ æ›´å¤šç»Ÿè®¡æŒ‡æ ‡

---

## ç›¸å…³èµ„æº

- [Pearson ç›¸å…³ç³»æ•°](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)
- [åŸºé‡‘æŠ•èµ„ç»„åˆç†è®º](https://en.wikipedia.org/wiki/Modern_portfolio_theory)
- [Pandas æ•°æ®åˆå¹¶](https://pandas.pydata.org/docs/reference/api/pandas.merge.html)

